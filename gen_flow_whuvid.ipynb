{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tq\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from multiprocessing import Pool\n",
    "import shutil\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import ReLU\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torchmetrics import JaccardIndex\n",
    "import threading\n",
    "\n",
    "import json\n",
    "\n",
    "# import segmentation_models_pytorch as smp\n",
    "# from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "# preprocess_input = get_preprocessing_fn('resnet34', pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: torch_scatter not found. CSV requires torch_scatter library to run. Check instructions at: https://github.com/rusty1s/pytorch_scatter\n"
     ]
    }
   ],
   "source": [
    "import ptlflow\n",
    "from ptlflow.utils import flow_utils\n",
    "from ptlflow.utils.io_adapter import IOAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/thiago/Workspace/motion-segmentation/datasets/WHUVID\"\n",
    "# sequences = [\"01\", \"02\", \"03\", \"17\", \"18\", \"19\", \"20\", \"22\", \"23\", \"24\", \"25\", \"30\", \"31\", \"32\"]\n",
    "sequences = [\"02\"]\n",
    "# sequences = [\"01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_list_from_file(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "    # remove first 3 (header)\n",
    "    return lines[3:]\n",
    "\n",
    "def get_next_image_path(image_list, image_path, diff):\n",
    "    # find index of image_path in image_list\n",
    "    # remove everything before \"cam0\"\n",
    "    relative_path = image_path[image_path.find(\"cam0\"):]\n",
    "    # get everything before cam0\n",
    "    root = image_path[:image_path.find(\"cam0\")]\n",
    "    idx = image_list.index(relative_path)\n",
    "    # return None if image_path is one of the last images\n",
    "    image_diff = diff\n",
    "    if idx >= (len(image_list) - image_diff):\n",
    "        return None\n",
    "    next_image_path = os.path.join(root, image_list[idx+image_diff])\n",
    "    # check if image exists\n",
    "    if not os.path.exists(next_image_path):\n",
    "        return None\n",
    "    return next_image_path\n",
    "\n",
    "def get_files(root_path, cam):\n",
    "    images = []\n",
    "    image_list = image_list_from_file(os.path.join(root_path, \"other_files/image.txt\"))\n",
    "    images_path = os.path.join(root_path, cam)\n",
    "    for root, dirs, files in os.walk(images_path):\n",
    "        for file in files:\n",
    "            full_path = os.path.join(root, file)\n",
    "            next_image = get_next_image_path(image_list, full_path, 10)\n",
    "            if full_path.endswith(\".png\")and next_image is not None:\n",
    "                # prevent !_src.empty()\n",
    "                # img = cv2.imread(full_path)\n",
    "                # if img is None:\n",
    "                #     continue\n",
    "                images.append(full_path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for seq in sequences:\n",
    "    path = os.path.join(root_path, seq)\n",
    "    images += get_files(path, \"cam0\")\n",
    "    flow_dir = os.path.join(path, \"flow_v7\", \"cam0\")\n",
    "    if not os.path.exists(flow_dir):\n",
    "        os.makedirs(flow_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8621"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_of_flow_image(image_path):\n",
    "    # remove everything before \"cam0\"\n",
    "    relative_path = image_path[image_path.find(\"cam0\"):]\n",
    "    # get everything before cam0\n",
    "    root = image_path[:image_path.find(\"cam0\")]\n",
    "    flow_path = os.path.join(root, \"flow_v7\", relative_path)\n",
    "    return flow_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiago/Workspace/motion-segmentation/src/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'loss_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_fn'])`.\n"
     ]
    }
   ],
   "source": [
    "model = ptlflow.get_model('dicl', pretrained_ckpt='kitti').cuda()\n",
    "# model = ptlflow.get_model('raft', pretrained_ckpt='kitti').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5e04456ab345a19e4aae94e9ccea67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8621 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flow_single_image(path):\n",
    "    try:\n",
    "        flow_path = get_path_of_flow_image(path)\n",
    "        # extract dir and create if not exists\n",
    "        # flow_dir = os.path.dirname(flow_path)\n",
    "        # recursively remove flow_dir\n",
    "        # if not os.path.exists(flow_dir):\n",
    "        #     os.makedirs(flow_dir, exist_ok=True)\n",
    "        # get next image name\n",
    "        # root_path is all before \"cam0\"\n",
    "        root_path = path[:path.find(\"cam0\")]\n",
    "        image_list = image_list_from_file(os.path.join(root_path, \"other_files/image.txt\"))\n",
    "        next_image_path = get_next_image_path(image_list, path, 10)\n",
    "        # compute flow\n",
    "        if next_image_path is None:\n",
    "            return\n",
    "        prev_image = cv2.imread(path)\n",
    "        next_image = cv2.imread(next_image_path)\n",
    "\n",
    "        height, width, _ = prev_image.shape\n",
    "        factor = 1.5\n",
    "        target_height, target_width = round(height//factor), round(width//factor)\n",
    "        # target_height, target_width = height, width\n",
    "        prev_image = cv2.resize(prev_image, (target_width, target_height))\n",
    "        next_image = cv2.resize(next_image, (target_width, target_height))\n",
    "\n",
    "        imgs = [prev_image, next_image]\n",
    "        io_adapter = IOAdapter(model, imgs[0].shape[:2])\n",
    "        inputs = io_adapter.prepare_inputs(imgs)\n",
    "        inputs['images'] = inputs['images'].cuda()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "        flows = predictions['flows']\n",
    "        flow_rgb = flow_utils.flow_to_rgb(flows, flow_max_radius=150)\n",
    "        # Make it a numpy array with HWC shape\n",
    "        flow_rgb = flow_rgb[0, 0].permute(1, 2, 0)\n",
    "        flow = flow_rgb.detach().cpu().numpy()\n",
    "        # OpenCV uses BGR format\n",
    "        flow = cv2.cvtColor(flow, cv2.COLOR_RGB2BGR)\n",
    "        # to 0-255\n",
    "        flow = (flow * 255).astype(np.uint8)\n",
    "        # return to original size\n",
    "        flow = cv2.resize(flow, (width, height))\n",
    "        # save flow image\n",
    "        cv2.imwrite(flow_path, flow)\n",
    "        \n",
    "        \n",
    "        # free memory\n",
    "        del prev_image\n",
    "        del next_image\n",
    "        del flow\n",
    "        del flow_rgb\n",
    "        del flows\n",
    "        del predictions\n",
    "        del inputs\n",
    "        del imgs\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {path} due to {e}\\n\")\n",
    "# using pool, with tqdm\n",
    "# with Pool(28) as p:\n",
    "#     list(tq.tqdm(p.imap(flow_single_image, images), total=len(images)))\\\n",
    "\n",
    "# without pool\n",
    "for i, image in tq.tqdm(enumerate(images), total=len(images)):\n",
    "    flow_single_image(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
