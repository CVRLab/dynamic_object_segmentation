{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tq\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "from torch.nn import ReLU\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "import threading\n",
    "\n",
    "import json\n",
    "\n",
    "from semseg import show_models\n",
    "from semseg.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.008151865817142985, 0.9996605296342409, -0.024746162835626976, 0.022009642363225456]\n",
    "# [0.9999404077919916, -0.007969450652357784, 0.007461147437525375, -0.0018523410930785084]\n",
    "# [0.00726140127552204, -0.0248055104298965, -0.9996659235483758, -0.023070561867408388]\n",
    "# [0.0, 0.0, 0.0, 1.0]\n",
    "T_cam_imu = np.array([\n",
    "    [0.008151865817142985, 0.9996605296342409, -0.024746162835626976, 0.022009642363225456],\n",
    "    [0.9999404077919916, -0.007969450652357784, 0.007461147437525375, -0.0018523410930785084],\n",
    "    [0.00726140127552204, -0.0248055104298965, -0.9996659235483758, -0.023070561867408388],\n",
    "    [0.0, 0.0, 0.0, 1.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whuvid_dataset import WhuvidDataset\n",
    "from kitti_dataset import KittiDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 512, 512\n",
    "# height, width = 256, 256\n",
    "with_augs = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(size=(height, width), scale=(0.2, 1.0), ratio=(0.5, 2)),\n",
    "    # transforms.Resize((height, width)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomRotation(10),\n",
    "    # transforms.RandomResizedCrop(size=224, scale=(0.4, 1.0)\n",
    "    #                             #  , ratio=(0.5, 2)\n",
    "    #                              ),\n",
    "    # resize to 224x224\n",
    "    # transforms.Resize((512, 512)),\n",
    "    # transforms.Resize((height, width)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whuvid_base_path = \"/home/thiago/Workspace/motion-segmentation/datasets/WHUVID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33 and 25 removed due to duplicated timestamps on pose ground truth\n",
    "# whuvid_dataset = WhuvidDataset(whuvid_base_path, [\"01\", \"16\", \"17\", \"22\", \"30\", \"31\", \"32\"], transform\n",
    "\n",
    "whuvid_train_dataset = WhuvidDataset(whuvid_base_path, [\"01\", \"02\", \"17\", \"19\", \"20\", \"23\", \"24\", \"25\", \"30\", \"31\", \"32\"], with_augs, segmentation=True, flow=True)\n",
    "val_dataset = WhuvidDataset(whuvid_base_path, [\"01\", \"02\", \"17\", \"19\", \"20\", \"23\", \"24\", \"25\", \"30\", \"31\", \"32\"], transform, segmentation=True, flow=True)\n",
    "# train_dataset = whuvid_train_dataset\n",
    "kitti_path = \"/home/thiago/Workspace/motion-segmentation/datasets/KITTI-Motion\"\n",
    "kitti = KittiDataset(kitti_path, with_augs, is_train=True, segmentation=True, flow=True)\n",
    "# print(f\"Kiti size: {len(kitti)}\")\n",
    "train_dataset = torch.utils.data.ConcatDataset([whuvid_train_dataset, kitti])\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 3\n",
    "\n",
    "def get_binary_masks(pred):\n",
    "    predicted_classes = np.argmax(pred, axis=0)\n",
    "    masks = []\n",
    "    for i in range(num_classes):\n",
    "        mask = (predicted_classes == i).astype(np.uint8)\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "def to_painted_image(image, label):\n",
    "    green_image = np.zeros_like(image)\n",
    "    blue_image = np.zeros_like(image)\n",
    "    green_image[:, :] = [0, 255, 0]  # Green color in BGR\n",
    "    blue_image[:, :] = [0, 0, 255]   # Blue color in BGR\n",
    "\n",
    "    masks = get_binary_masks(label)\n",
    "\n",
    "    alpha = 0.998  # Alpha value for blending\n",
    "    beta = 1.0 - alpha\n",
    "    blended_green = cv2.addWeighted(image, alpha, green_image, beta, 0)\n",
    "    blended_blue = cv2.addWeighted(image, alpha, blue_image, beta, 0)\n",
    "    blended_green = np.clip(blended_green, 0, 1)\n",
    "    blended_blue = np.clip(blended_blue, 0, 1)\n",
    "\n",
    "    output_image = image.copy()\n",
    "    output_image[masks[0] == 1] = blended_blue[masks[0] == 1]\n",
    "    output_image[masks[1] == 1] = blended_green[masks[1] == 1]\n",
    "\n",
    "    return output_image\n",
    "\n",
    "def print_dataset(dataset, i):\n",
    "    img, flow, imu, mask = dataset[i]\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    mask = mask.numpy()\n",
    "    flow = flow.permute(1, 2, 0).numpy()\n",
    "    flow = flow * 255\n",
    "    img_painted = to_painted_image(img, mask)\n",
    "    # print image and flow\n",
    "    # fig, ax = plt.subplots(1, 2, figsize=(7.5, 5))\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    ax[0].imshow(img_painted)\n",
    "    ax[0].set_title(\"Image Annotated\")\n",
    "    ax[1].imshow(flow)\n",
    "    ax[1].set_title(\"Flow\")\n",
    "    plt.show()\n",
    "\n",
    "def view_masks(dataset, i):\n",
    "    img, flow, imu, mask, bbox = dataset[i]\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    # draw bounding boxes on img\n",
    "    img_bb = img.copy()\n",
    "    for b in bbox:\n",
    "        # to int\n",
    "        x1, y1, x2, y2 = [int(i) for i in b]\n",
    "        cv2.rectangle(img_bb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    mask = mask.numpy()\n",
    "    # show image, mask[0] and mask[1]. Masks are binary, Show black and white\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    ax[0].imshow(img_bb)\n",
    "    ax[0].set_title(\"Imagem\")\n",
    "    ax[1].imshow(mask[0], cmap='gray')\n",
    "    ax[1].set_title(\"Em movimento\")\n",
    "    ax[2].imshow(mask[1], cmap='gray')\n",
    "    ax[2].set_title(\"Parado\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = random.randint(0, len(train_dataset)-1)\n",
    "print_dataset(train_dataset, random_index)\n",
    "height, width = train_dataset[0][0].shape[1:]\n",
    "\n",
    "random_index = random.randint(0, len(val_dataset)-1)\n",
    "print_dataset(val_dataset, random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_index = random.randint(0, len(kitti)-1)\n",
    "print_dataset(kitti, random_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view_seq = \"22\"\n",
    "view_transform = transforms.Compose([\n",
    "    transforms.Resize((height, width)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "view_seq = WhuvidDataset(whuvid_base_path, [view_seq], view_transform, segmentation=True, flow=True, use_gdino=False, use_bbox=True)\n",
    "view_masks(view_seq, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  10\n",
    "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=12, drop_last=True)\n",
    "test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=24, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semseg.models.backbones import ResNet, PoolFormer, ConvNeXt\n",
    "from semseg.models.heads import UPerHead, LawinHead\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class SemSegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.print_shape = True\n",
    "        self.backbone_flow = ResNet('18')\n",
    "        self.backbone_flow.load_state_dict(torch.load('../models/resnet18_a1.pth',\n",
    "                                                        map_location='cpu'), strict=False)\n",
    "        self.backbone_img = ResNet('50')\n",
    "        self.backbone_img.load_state_dict(torch.load('/home/thiago/Workspace/motion-segmentation/src/resnet50_a1.pth',\n",
    "                                                        map_location='cuda'), strict=False)\n",
    "        \n",
    "        backbone_channels = self.backbone_img.channels + self.backbone_flow.channels\n",
    "\n",
    "        print(backbone_channels)\n",
    "        self.head = LawinHead(backbone_channels, 128, num_classes=num_classes)\n",
    "    \n",
    "    def forward(self, img, flow, imu):\n",
    "        img_x = self.backbone_img(img)\n",
    "        flow_x = self.backbone_flow(flow)\n",
    "        \n",
    "        if self.print_shape:\n",
    "            for i in img_x:\n",
    "                print(f\"Img shape: {i.shape}\")\n",
    "            for i in flow_x:\n",
    "                print(f\"Flow shape: {i.shape}\")\n",
    "   \n",
    "        x = img_x + flow_x\n",
    "   \n",
    "        x = self.head(x)\n",
    "        \n",
    "        if self.print_shape:\n",
    "            print(f\"Output shape: {x.shape}\")\n",
    "            self.print_shape = False\n",
    "        \n",
    "        x = F.interpolate(x, size=(height, width), mode='bilinear', align_corners=False)\n",
    "        return x\n",
    "\n",
    "model = SemSegModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataset(train_dataset, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "# initialize loss function and optimizer\n",
    "pos_weight = torch.tensor([4, 4, 1]).unsqueeze(1).unsqueeze(2).to(device)\n",
    "# pos_weight = torch.tensor([5, 5, 1]).to(device)\n",
    "# lossFunc = BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "alpha = 0.75\n",
    "gamma = 2\n",
    "lossFunc = torchvision.ops.focal_loss.sigmoid_focal_loss\n",
    "# opt = Adam(model.parameters(), lr=1e-3)\n",
    "opt = torch.optim.AdamW(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=0.00005,\n",
    "                                                steps_per_epoch=len(data_loader), epochs=num_epochs)\n",
    "trainSteps = len(train_dataset) // batch_size\n",
    "testSteps = len(val_dataset) // batch_size\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [], \"test_loss\": [], \"train_iou\": [], \"test_iou\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(output, target):\n",
    "    output = torch.where(output > 0.5, 1, 0)\n",
    "    target = torch.where(target > 0.5, 1, 0)\n",
    "\n",
    "    smooth = 1e-6\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = torch.sigmoid(output)\n",
    "\n",
    "    output = torch.round(output)\n",
    "\n",
    "    intersection = (output * target).sum()\n",
    "    union = (output + target).sum() - intersection\n",
    "\n",
    "    if target.sum() == 0:\n",
    "        return (output.sum() == 0).float()\n",
    "\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "# bestValIoU = 0\n",
    "bestTestLoss = 100000000\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for e in tq.tqdm(range(0, num_epochs)):\n",
    "\t# set the model in training mode\n",
    "\tmodel.train()\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalTestLoss = 0\n",
    "\tiou_train_acm = list(0 for i in range(num_classes))\n",
    "\tiou_train_count = 0\n",
    "\tiou_test_acm = list(0 for i in range(num_classes))\n",
    "\tiou_test_count = 0\n",
    "\n",
    "\ttrain_bar = tq.tqdm(data_loader)\n",
    "\tfor batch in train_bar:\n",
    "\t\topt.zero_grad()\n",
    "\t\timg, flow, imu, y = batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device)\n",
    "\n",
    "\t\tpred = model(img, flow, imu)\n",
    "\n",
    "\t\tloss = lossFunc(pred, y, reduction='mean', alpha=alpha, gamma=gamma)\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\t\tscheduler.step()\n",
    "\n",
    "\t\ttotalTrainLoss += loss.item()\n",
    "\t\t# totalTrainIoU += iou\n",
    "\t\tiou_train = [iou_score(pred[:,i], y[:,i]).item() for i in range(num_classes)]\n",
    "\t\tiou_train_acm = [iou_train_acm[i] + iou_train[i] for i in range(num_classes)]\n",
    "\t\tiou_train_count += 1\n",
    "\t\tiou_train_avg = [iou_train_acm[i] / iou_train_count for i in range(num_classes)]\n",
    "\n",
    "\t\tmetrics = {f\"iou[{i}]\": iou_train_avg[i] for i in range(num_classes)}\n",
    "\t\ttrain_bar.set_postfix(metrics)\n",
    "\t# switch off autograd\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tmodel.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\ttest_bar = tq.tqdm(test_loader)\n",
    "\t\tfor batch in test_bar:\n",
    "\t\t\timg, flow, imu, y = batch[0].to(device), batch[1].to(device), batch[2].to(device), batch[3].to(device)\n",
    "\n",
    "\t\t\tpred = model(img, flow, imu)\n",
    "\t\t\t# pred = unet(inputs)\n",
    "\t\t\ttotalTestLoss += lossFunc(pred, y, reduction='mean', alpha=alpha, gamma=gamma).item()\n",
    "\n",
    "\t\t\tiou_test = [iou_score(pred[:,i], y[:,i]).item() for i in range(num_classes)]\n",
    "\t\t\tiou_test_acm = [iou_test_acm[i] + iou_test[i] for i in range(num_classes)]\n",
    "\t\t\tiou_test_count += 1\n",
    "\t\t\tiou_test_avg = [iou_test_acm[i] / iou_test_count for i in range(num_classes)]\n",
    "\t\t\tmetrics = {f\"iou[{i}]\": iou_test_avg[i] for i in range(num_classes)}\n",
    "\t\t\ttest_bar.set_postfix(metrics)\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgTestLoss = totalTestLoss / testSteps\n",
    "\t\n",
    "\tiou_train_avg = [iou_train_acm[i] / (iou_train_count + 1) for i in range(num_classes)]\n",
    "\tiou_test_avg = [iou_test_acm[i] / (iou_test_count + 1) for i in range(num_classes)]\n",
    "\t# update our training history\n",
    "\tH[\"train_loss\"].append(avgTrainLoss)\n",
    "\tH[\"test_loss\"].append(avgTestLoss)\n",
    "\tH[\"train_iou\"].append(iou_train_avg[0])\n",
    "\tH[\"test_iou\"].append(iou_test_avg[0])\n",
    "\t# print the model training and validation information\n",
    "\tprint(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(avgTrainLoss, avgTestLoss))\n",
    "\t\n",
    "\tfor i in range(num_classes):\n",
    "\t\tprint(f\"IoU[{i}] Train: {iou_train_avg[i]}, IoU[{i}] Test: {iou_test_avg[i]}\")\n",
    "\tif not os.path.exists(\"models\"):\n",
    "\t\tos.mkdir(\"models\")\n",
    "\ttorch.save(model, f\"models/motion-seg-{e}.pth\")\n",
    "\tif avgTestLoss < bestTestLoss:\n",
    "\t\tbestTestLoss = avgTestLoss\n",
    "\t\tprint(f\"Saving epoch {e} with loss {avgTestLoss}\")\n",
    "\t\ttorch.save(model, f\"models/best-loss.pth\")\n",
    "\ttorch.save(model, f\"models/latest.pth\")\n",
    "\t\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "\tendTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"models/last.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
